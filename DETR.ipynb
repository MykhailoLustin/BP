{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modelovanie a vyhodnotenie DETR\n",
        "\n",
        "**Poznámka:** Aby sme si uľahčili prácu so súbormi údajov, obrázkami a modelmi, vytvoríme konštantu `HOME`."
      ],
      "metadata": {
        "id": "qGbtXNqjk5AK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idyl7Hltwev8",
        "outputId": "1717f9e6-437a-4f25-9278-bb13b3972370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ1xdhF9epQ5"
      },
      "source": [
        "## Nastavenie prostredia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1s3GNNh3yKkL"
      },
      "outputs": [],
      "source": [
        "!pip install -i https://test.pypi.org/simple/ supervision==0.3.0\n",
        "!pip install -q transformers\n",
        "!pip install -q pytorch-lightning\n",
        "!pip install -q timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkBxWG_koPsg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "\n",
        "import supervision\n",
        "import transformers\n",
        "import pytorch_lightning\n",
        "\n",
        "print(\n",
        "    \"; supervision:\", supervision.__version__,\n",
        "    \"; transformers:\", transformers.__version__,\n",
        "    \"; pytorch_lightning:\", pytorch_lightning.__version__\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHQTqHsQgsCZ"
      },
      "source": [
        "### Načítanie modelu DETR do premennej `CHECKPOINT`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w70Rgx-ydq2L"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import DetrForObjectDetection, DetrImageProcessor\n",
        "import supervision as sv\n",
        "\n",
        "# settings\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "CHECKPOINT = 'facebook/detr-resnet-50'\n",
        "CONFIDENCE_TRESHOLD = 0.5\n",
        "IOU_TRESHOLD = 0.8\n",
        "\n",
        "image_processor = DetrImageProcessor.from_pretrained(CHECKPOINT)\n",
        "model = DetrForObjectDetection.from_pretrained(CHECKPOINT)\n",
        "model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_location = 'Meteory_format_COCO_aug'"
      ],
      "metadata": {
        "id": "tUUd3upqnuXW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vytváranie dátových loaderov (DataLoader) na trénovanie, validáciu a testovanie modelu"
      ],
      "metadata": {
        "id": "3NmyvBsHv1qB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk6sRB0lueHY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# settings\n",
        "ANNOTATION_FILE_NAME = \"_annotations.coco.json\"\n",
        "TRAIN_DIRECTORY = os.path.join(dataset_location, \"train\")\n",
        "VAL_DIRECTORY = os.path.join(dataset_location, \"valid\")\n",
        "TEST_DIRECTORY = os.path.join(dataset_location, \"test\")\n",
        "\n",
        "\n",
        "class CocoDetection(torchvision.datasets.CocoDetection):\n",
        "    def __init__(\n",
        "        self,\n",
        "        image_directory_path: str,\n",
        "        image_processor,\n",
        "        train: bool = True\n",
        "    ):\n",
        "        annotation_file_path = os.path.join(image_directory_path, ANNOTATION_FILE_NAME)\n",
        "        super(CocoDetection, self).__init__(image_directory_path, annotation_file_path)\n",
        "        self.image_processor = image_processor\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        images, annotations = super(CocoDetection, self).__getitem__(idx)\n",
        "        image_id = self.ids[idx]\n",
        "        annotations = {'image_id': image_id, 'annotations': annotations}\n",
        "        encoding = self.image_processor(images=images, annotations=annotations, return_tensors=\"pt\")\n",
        "        pixel_values = encoding[\"pixel_values\"].squeeze()\n",
        "        target = encoding[\"labels\"][0]\n",
        "\n",
        "        return pixel_values, target\n",
        "\n",
        "\n",
        "TRAIN_DATASET = CocoDetection(\n",
        "    image_directory_path=TRAIN_DIRECTORY,\n",
        "    image_processor=image_processor,\n",
        "    train=True)\n",
        "VAL_DATASET = CocoDetection(\n",
        "    image_directory_path=VAL_DIRECTORY,\n",
        "    image_processor=image_processor,\n",
        "    train=False)\n",
        "TEST_DATASET = CocoDetection(\n",
        "    image_directory_path=TEST_DIRECTORY,\n",
        "    image_processor=image_processor,\n",
        "    train=False)\n",
        "\n",
        "def collate_fn(batch):\n",
        "\n",
        "    pixel_values = [item[0] for item in batch]\n",
        "    encoding = image_processor.pad(pixel_values, return_tensors=\"pt\")\n",
        "    labels = [item[1] for item in batch]\n",
        "    return {\n",
        "        'pixel_values': encoding['pixel_values'],\n",
        "        'pixel_mask': encoding['pixel_mask'],\n",
        "        'labels': labels\n",
        "    }\n",
        "\n",
        "TRAIN_DATALOADER = DataLoader(dataset=TRAIN_DATASET, collate_fn=collate_fn, batch_size=16, shuffle=True)\n",
        "VAL_DATALOADER = DataLoader(dataset=VAL_DATASET, collate_fn=collate_fn, batch_size=16)\n",
        "TEST_DATALOADER = DataLoader(dataset=TEST_DATASET, collate_fn=collate_fn, batch_size=16)\n",
        "\n",
        "categories = TEST_DATASET.coco.cats\n",
        "id2label = {k: v['name'] for k,v in categories.items()}\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "\n",
        "print(\"Number of training examples:\", len(TRAIN_DATASET))\n",
        "print(\"Number of validation examples:\", len(VAL_DATASET))\n",
        "print(\"Number of test examples:\", len(TEST_DATASET))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vVPm-sO4C9W"
      },
      "source": [
        "## Tréning modelu pomocou PyTorch Lightning\n",
        "\n",
        "### DETR implementovaný pomocou PyTorch Lightning bez Optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "from transformers import DetrForObjectDetection\n",
        "import torch\n",
        "\n",
        "# Definícia triedy Detr\n",
        "class Detr(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, lr, lr_backbone, weight_decay):\n",
        "        super().__init__()\n",
        "        # Načítanie predtrénovanej modelu DETR pre detekciu objektov\n",
        "        self.model = DetrForObjectDetection.from_pretrained(\n",
        "            pretrained_model_name_or_path=CHECKPOINT,  # Premenná CHECKPOINT obsahuje cestu k predtrénovanému modelu\n",
        "            num_labels=len(id2label),  # Počet tried (etikiet) objektov v dátach\n",
        "            ignore_mismatched_sizes=True  # Ignorovanie nezhôd veľkostí obrázkov\n",
        "        )\n",
        "\n",
        "        # Inicializácia parametrov učenia\n",
        "        self.lr = lr\n",
        "        self.lr_backbone = lr_backbone\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "    # Dopredu (forward) funkcia modelu\n",
        "    def forward(self, pixel_values, pixel_mask):\n",
        "        return self.model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
        "\n",
        "    # Spoločná funkcia pre krok (step) trénovania a validácie\n",
        "    def common_step(self, batch, batch_idx):\n",
        "        pixel_values = batch[\"pixel_values\"]\n",
        "        pixel_mask = batch[\"pixel_mask\"]\n",
        "        labels = [{k: v.to(self.device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
        "\n",
        "        # Výpočet predikcií a straty\n",
        "        outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss_dict = outputs.loss_dict\n",
        "\n",
        "        return loss, loss_dict\n",
        "\n",
        "    # Trénovací krok\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, loss_dict = self.common_step(batch, batch_idx)\n",
        "        # Logovanie metrík pre každý trénovací krok a priemerná hodnota počas epochy\n",
        "        self.log(\"training_loss\", loss)\n",
        "        for k,v in loss_dict.items():\n",
        "            self.log(\"train_\" + k, v.item())\n",
        "\n",
        "        return loss\n",
        "\n",
        "    # Validácia krok\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss, loss_dict = self.common_step(batch, batch_idx)\n",
        "        self.log(\"validation/loss\", loss)\n",
        "        for k, v in loss_dict.items():\n",
        "            self.log(\"validation_\" + k, v.item())\n",
        "\n",
        "        return loss\n",
        "\n",
        "    # Konfigurácia optimalizátorov\n",
        "    def configure_optimizers(self):\n",
        "        param_dicts = [\n",
        "            {\n",
        "                \"params\": [p for n, p in self.named_parameters() if \"backbone\" not in n and p.requires_grad]},\n",
        "            {\n",
        "                \"params\": [p for n, p in self.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
        "                \"lr\": self.lr_backbone,\n",
        "            },\n",
        "        ]\n",
        "        return torch.optim.AdamW(param_dicts, lr=self.lr, weight_decay=self.weight_decay)\n",
        "\n",
        "    # DataLoader pre trénovacie dáta\n",
        "    def train_dataloader(self):\n",
        "        return TRAIN_DATALOADER\n",
        "\n",
        "    # DataLoader pre validačné dáta\n",
        "    def val_dataloader(self):\n",
        "        return VAL_DATALOADER\n",
        "\n",
        "model = Detr(lr=1e-4, lr_backbone=1e-5, weight_decay=1e-4)\n",
        "\n",
        "batch = next(iter(TRAIN_DATALOADER))\n",
        "outputs = model(pixel_values=batch['pixel_values'], pixel_mask=batch['pixel_mask'])\n",
        "outputs.logits.shape"
      ],
      "metadata": {
        "id": "_vmANsy43IDG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-cJEJvAGjTB"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning import Trainer\n",
        "\n",
        "%cd {HOME}\n",
        "\n",
        "MAX_EPOCHS = 100\n",
        "\n",
        "trainer = Trainer(devices=1, accelerator=\"gpu\", max_epochs=MAX_EPOCHS, gradient_clip_val=0.1, accumulate_grad_batches=8, log_every_n_steps=5)\n",
        "\n",
        "trainer.fit(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DETR implementovaný pomocou PyTorch Lightning s Optuna"
      ],
      "metadata": {
        "id": "uyTExEI74lwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install coco_eval\n",
        "!pip install optuna"
      ],
      "metadata": {
        "id": "4tWz57Ws5Urm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "from transformers import DetrForObjectDetection\n",
        "import torch\n",
        "from coco_eval import CocoEvaluator\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# Trieda Detr rozširuje PyTorch Lightning Module\n",
        "class Detr(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, lr, lr_backbone, weight_decay, num_encoder_layers, num_decoder_layers):\n",
        "        super().__init__()\n",
        "        # Načítanie predtrénovaného modelu DETR pre detekciu objektov\n",
        "        self.model = DetrForObjectDetection.from_pretrained(\n",
        "            pretrained_model_name_or_path=CHECKPOINT,  # Premenná CHECKPOINT obsahuje cestu k predtrénovanému modelu\n",
        "            num_labels=len(id2label),  # Počet tried objektov v dátach\n",
        "            ignore_mismatched_sizes=True  # Ignorovanie nezhôd veľkostí obrázkov\n",
        "        )\n",
        "\n",
        "        # Inicializácia parametrov učenia\n",
        "        self.lr = lr\n",
        "        self.lr_backbone = lr_backbone\n",
        "        self.weight_decay = weight_decay\n",
        "        self.num_encoder_layers = num_encoder_layers\n",
        "        self.num_decoder_layers = num_decoder_layers\n",
        "\n",
        "        # Nastavenie počtu vrstiev enkodera a dekodera modelu\n",
        "        self.model.config.encoder_layers = num_encoder_layers\n",
        "        self.model.config.decoder_layers = num_decoder_layers\n",
        "\n",
        "    # Forward funkcia modelu\n",
        "    def forward(self, pixel_values, pixel_mask):\n",
        "        return self.model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
        "\n",
        "    # Spoločná funkcia pre krok (step) trénovania a validácie\n",
        "    def common_step(self, batch, batch_idx):\n",
        "        pixel_values = batch[\"pixel_values\"]\n",
        "        pixel_mask = batch[\"pixel_mask\"]\n",
        "        labels = [{k: v.to(self.device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
        "\n",
        "        # Výpočet predikcií a straty\n",
        "        outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss_dict = outputs.loss_dict\n",
        "\n",
        "        return loss, loss_dict\n",
        "\n",
        "    # Trénovací krok\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, loss_dict = self.common_step(batch, batch_idx)\n",
        "        self.log(\"training_loss\", loss)\n",
        "        for k, v in loss_dict.items():\n",
        "            self.log(\"train_\" + k, v.item())\n",
        "\n",
        "        return loss\n",
        "\n",
        "    # Validácia krok\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss, loss_dict = self.common_step(batch, batch_idx)\n",
        "        self.log(\"validation/loss\", loss)\n",
        "        for k, v in loss_dict.items():\n",
        "            self.log(\"validation_\" + k, v.item())\n",
        "\n",
        "        return loss\n",
        "\n",
        "    # Konfigurácia optimalizátorov\n",
        "    def configure_optimizers(self):\n",
        "        param_dicts = [\n",
        "            {\n",
        "                \"params\": [p for n, p in self.named_parameters() if \"backbone\" not in n and p.requires_grad]\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in self.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
        "                \"lr\": self.lr_backbone,\n",
        "            },\n",
        "        ]\n",
        "        return torch.optim.AdamW(param_dicts, lr=self.lr, weight_decay=self.weight_decay)\n",
        "\n",
        "    # DataLoader pre trénovacie dáta\n",
        "    def train_dataloader(self):\n",
        "        return TRAIN_DATALOADER\n",
        "\n",
        "    # DataLoader pre validačné dáta\n",
        "    def val_dataloader(self):\n",
        "        return VAL_DATALOADER\n",
        "\n",
        "# Funkcia na konverziu koordinátov boxes na formát xywh\n",
        "def convert_to_xywh(boxes):\n",
        "    xmin, ymin, xmax, ymax = boxes.unbind(1)\n",
        "    return torch.stack((xmin, ymin, xmax - xmin, ymax - ymin), dim=1)\n",
        "\n",
        "# Funkcia na prípravu výstupov modelu pre detekciu objektov pre evaluáciu pomocou COCO metriky\n",
        "def prepare_for_coco_detection(predictions):\n",
        "    coco_results = []\n",
        "    for original_id, prediction in predictions.items():\n",
        "        if len(prediction) == 0:\n",
        "            continue\n",
        "\n",
        "        boxes = prediction[\"boxes\"]\n",
        "        boxes = convert_to_xywh(boxes).tolist()\n",
        "        scores = prediction[\"scores\"].tolist()\n",
        "        labels = prediction[\"labels\"].tolist()\n",
        "\n",
        "        coco_results.extend(\n",
        "            [\n",
        "                {\n",
        "                    \"image_id\": original_id,\n",
        "                    \"category_id\": labels[k],\n",
        "                    \"bbox\": box,\n",
        "                    \"score\": scores[k],\n",
        "                }\n",
        "                for k, box in enumerate(boxes)\n",
        "            ]\n",
        "        )\n",
        "    return coco_results\n",
        "\n",
        "# Funkcia pre vyhodnotenie modelu\n",
        "def eva():\n",
        "    evaluator = CocoEvaluator(coco_gt=VAL_DATASET.coco, iou_types=[\"bbox\"])\n",
        "\n",
        "    print(\"Running evaluation...\")\n",
        "\n",
        "    for idx, batch in enumerate(tqdm(VAL_DATALOADER)):\n",
        "        pixel_values = batch[\"pixel_values\"].to(DEVICE)\n",
        "        pixel_mask = batch[\"pixel_mask\"].to(DEVICE)\n",
        "        labels = [{k: v.to(DEVICE) for k, v in t.items()} for t in batch[\"labels\"]]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
        "\n",
        "        orig_target_sizes = torch.stack([target[\"orig_size\"] for target in labels], dim=0)\n",
        "        results = image_processor.post_process_object_detection(outputs, target_sizes=orig_target_sizes)\n",
        "\n",
        "        predictions = {target['image_id'].item(): output for target, output in zip(labels, results)}\n",
        "        predictions = prepare_for_coco_detection(predictions)\n",
        "        evaluator.update(predictions)\n",
        "\n",
        "    evaluator.synchronize_between_processes()\n",
        "    evaluator.accumulate()\n",
        "    evaluator.summarize()\n",
        "    coco_eval = evaluator.coco_eval['bbox']\n",
        "    ap50 = coco_eval.stats[1]  # AP at IoU=0.5 (AP50)\n",
        "    print(f\"AP50: {ap50:.4f}\")\n",
        "    return ap50\n"
      ],
      "metadata": {
        "id": "thcvNskx4lAp"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from optuna.samplers import GridSampler\n",
        "\n",
        "# Definícia priestoru vyhľadávania pre hyperparametre\n",
        "search_space = {\n",
        "    \"lr\": [0.0001, 0.0005],  # Learning rate\n",
        "    \"num_encoder_layers\": [4, 6],  # Počet vrstiev kódovača\n",
        "    \"num_decoder_layers\": [4, 6]   # Počet vrstiev dekódovača\n",
        "}\n",
        "\n",
        "# Objektívna funkcia pre optimalizáciu\n",
        "def objective(trial):\n",
        "    lr = trial.suggest_categorical('lr', [0.0001, 0.0005])  # Výber hodnoty pre learning rate z rozsahu\n",
        "    num_encoder_layers = trial.suggest_categorical('num_encoder_layers', [4, 6])  # Výber počtu vrstiev kódovača\n",
        "    num_decoder_layers = trial.suggest_categorical('num_decoder_layers', [4, 6])  # Výber počtu vrstiev dekódovača\n",
        "\n",
        "    # Vytvorenie modelu DETR s danými hyperparametrami\n",
        "    model = Detr(\n",
        "        lr=lr,\n",
        "        lr_backbone=1e-5,\n",
        "        weight_decay=1e-5,\n",
        "        num_encoder_layers=num_encoder_layers,\n",
        "        num_decoder_layers=num_decoder_layers\n",
        "    )\n",
        "    model = model.to(DEVICE)  # Presunutie modelu na dané zariadenie (GPU alebo CPU)\n",
        "\n",
        "    # Vytvorenie trénera pre trénovanie modelu\n",
        "    trainer = Trainer(\n",
        "        devices=1,  # Počet zariadení (1 pre GPU, 0 pre CPU)\n",
        "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",  # Akcelerátor (gpu alebo cpu)\n",
        "        max_epochs=100,  # Maximálny počet epoch pre trénovanie\n",
        "        gradient_clip_val=0.1,  # Hodnota pre orezanie gradientov\n",
        "        accumulate_grad_batches=8,  # Počet dávok pre akumuláciu gradientov\n",
        "        log_every_n_steps=5  # Logovanie každých N krokov\n",
        "    )\n",
        "\n",
        "    # Trénovanie modelu\n",
        "    trainer.fit(model)\n",
        "\n",
        "    model.to(DEVICE)  # Presunutie modelu späť na zariadenie (GPU alebo CPU)\n",
        "    ap = eva()  # Vykonanie evaluácie modelu a výpočet AP (Average Precision)\n",
        "\n",
        "    return ap  # Návrat hodnoty AP pre Optuna\n",
        "\n",
        "# Vytvorenie štúdie pre optimalizáciu smerom k maximalizácii\n",
        "study = optuna.create_study(direction='maximize', sampler=GridSampler(search_space))\n",
        "study.optimize(objective, n_trials=10)  # Spustenie optimalizácie pre 10 pokusov\n",
        "print(\"best params: \", study.best_params)  # Výpis najlepších hyperparametrov\n",
        "print(\"best AP: \", study.best_value)  # Výpis najlepšej dosiahnutej hodnoty AP\n"
      ],
      "metadata": {
        "id": "oIGXdRTb5Fw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrewgWdGQULA"
      },
      "source": [
        "## Inference na testovacom súbore údajov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6YfGgeATvbR"
      },
      "outputs": [],
      "source": [
        "model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbzTzHJW22up"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# pomocné funkcie\n",
        "categories = TEST_DATASET.coco.cats\n",
        "id2label = {k: v['name'] for k, v in categories.items()}  # Mapovanie ID tried na názvy tried\n",
        "box_annotator = sv.BoxAnnotator()  # Inicializácia anotátora pre ohraničujúce boxy\n",
        "\n",
        "# Prechádzanie všetkých obrázkov v testovacej sade\n",
        "for image_id in TEST_DATASET.coco.getImgIds():\n",
        "    print('Spracovanie obrázka #{}'.format(image_id))\n",
        "\n",
        "    # Načítanie obrázka a anotácií\n",
        "    image_info = TEST_DATASET.coco.loadImgs(image_id)[0]\n",
        "    annotations = TEST_DATASET.coco.imgToAnns[image_id]\n",
        "    image_path = os.path.join(TEST_DATASET.root, image_info['file_name'])\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Anotácia ground truth\n",
        "    detections = sv.Detections.from_coco_annotations(coco_annotation=annotations)\n",
        "    labels = [f\"{id2label[class_id]}\" for _, _, class_id, _ in detections]\n",
        "    frame = box_annotator.annotate(scene=image.copy(), detections=detections, labels=labels)\n",
        "\n",
        "    print('Ground Truth pre obrázok #{}'.format(image_id))\n",
        "    %matplotlib inline\n",
        "    sv.show_frame_in_notebook(frame, (16, 16))\n",
        "\n",
        "    # Inferencia\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Načítanie obrázka a predikcia\n",
        "        inputs = image_processor(images=image, return_tensors='pt').to(DEVICE)\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        # Post-processing\n",
        "        target_sizes = torch.tensor([image.shape[:2]]).to(DEVICE)\n",
        "        results = image_processor.post_process_object_detection(\n",
        "            outputs=outputs,\n",
        "            threshold=CONFIDENCE_TRESHOLD,\n",
        "            target_sizes=target_sizes\n",
        "        )[0]\n",
        "\n",
        "    # Anotácia detekcií\n",
        "    detections = sv.Detections.from_transformers(transformers_results=results).with_nms(threshold=0.5)\n",
        "    labels = [f\"{id2label[class_id]} {confidence:.2f}\" for _, confidence, class_id, _ in detections]\n",
        "    frame = box_annotator.annotate(scene=image.copy(), detections=detections, labels=labels)\n",
        "\n",
        "    print('Detekcie pre obrázok #{}'.format(image_id))\n",
        "    %matplotlib inline\n",
        "    sv.show_frame_in_notebook(frame, (16, 16))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y695PeIASOjF"
      },
      "source": [
        "## Vyhodnotenie na testovacom súbore údajov"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q coco_eval"
      ],
      "metadata": {
        "id": "fiEaI_vpSz2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2611648d-daf5-47e0-db87-511f1ea8da95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for coco_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from coco_eval import CocoEvaluator\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def convert_to_xywh(boxes):\n",
        "    xmin, ymin, xmax, ymax = boxes.unbind(1)\n",
        "    return torch.stack((xmin, ymin, xmax - xmin, ymax - ymin), dim=1)\n",
        "\n",
        "def prepare_for_coco_detection(predictions):\n",
        "    coco_results = []\n",
        "    for original_id, prediction in predictions.items():\n",
        "        if len(prediction) == 0:\n",
        "            continue\n",
        "\n",
        "        boxes = prediction[\"boxes\"]\n",
        "        boxes = convert_to_xywh(boxes).tolist()\n",
        "        scores = prediction[\"scores\"].tolist()\n",
        "        labels = prediction[\"labels\"].tolist()\n",
        "\n",
        "        coco_results.extend(\n",
        "            [\n",
        "                {\n",
        "                    \"image_id\": original_id,\n",
        "                    \"category_id\": labels[k],\n",
        "                    \"bbox\": box,\n",
        "                    \"score\": scores[k],\n",
        "                }\n",
        "                for k, box in enumerate(boxes)\n",
        "            ]\n",
        "        )\n",
        "    return coco_results\n",
        "\n",
        "evaluator = CocoEvaluator(coco_gt=TEST_DATASET.coco, iou_types=[\"bbox\"])\n",
        "\n",
        "print(\"Running evaluation...\")\n",
        "\n",
        "for idx, batch in enumerate(tqdm(TEST_DATALOADER)):\n",
        "    pixel_values = batch[\"pixel_values\"].to(DEVICE)\n",
        "    pixel_mask = batch[\"pixel_mask\"].to(DEVICE)\n",
        "    labels = [{k: v.to(DEVICE) for k, v in t.items()} for t in batch[\"labels\"]]\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
        "\n",
        "    orig_target_sizes = torch.stack([target[\"orig_size\"] for target in labels], dim=0)\n",
        "    results = image_processor.post_process_object_detection(outputs, target_sizes=orig_target_sizes)\n",
        "\n",
        "    predictions = {target['image_id'].item(): output for target, output in zip(labels, results)}\n",
        "    predictions = prepare_for_coco_detection(predictions)\n",
        "    evaluator.update(predictions)\n",
        "\n",
        "evaluator.synchronize_between_processes()\n",
        "evaluator.accumulate()\n",
        "evaluator.summarize()"
      ],
      "metadata": {
        "id": "pQx9pgaHVScS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}